import { GoogleGenAI, Part } from '@google/genai';
import { readFileSync, writeFileSync, mkdirSync } from 'fs';
import { join } from 'path';
import { MediaInfo, GenerateResult, ImageConfig } from '../types';

const MODEL_ID = 'gemini-3-pro-image-preview';

let ai: GoogleGenAI | null = null;

function getClient(): GoogleGenAI {
  if (!ai) {
    const apiKey = process.env.GEMINI_AI_KEY;
    if (!apiKey) {
      throw new Error('GEMINI_AI_KEY environment variable not set');
    }
    ai = new GoogleGenAI({ apiKey });
  }
  return ai;
}

function mediaToPart(media: MediaInfo): Part {
  const fileData = readFileSync(media.path);
  const base64Data = fileData.toString('base64');
  return {
    inlineData: {
      mimeType: media.mimeType,
      data: base64Data,
    },
  };
}

export async function analyzeMedia(media: MediaInfo, prompt: string): Promise<string> {
  const client = getClient();

  const mediaPart = mediaToPart(media);
  const textPart: Part = { text: prompt };

  const response = await client.models.generateContent({
    model: MODEL_ID,
    contents: [{ role: 'user', parts: [mediaPart, textPart] }],
    config: {
      temperature: 0,
    },
  });

  return response.text ?? '';
}

export async function analyzeMultipleMedia(mediaList: MediaInfo[], prompt: string): Promise<string> {
  const client = getClient();

  const parts: Part[] = mediaList.map((media) => mediaToPart(media));

  const textPart: Part = {
    text: `[Analyzing ${mediaList.length} files: ${mediaList.map(m => m.path.split('/').pop()).join(', ')}]\n\n${prompt}`,
  };
  parts.push(textPart);

  const response = await client.models.generateContent({
    model: MODEL_ID,
    contents: [{ role: 'user', parts }],
    config: {
      temperature: 0,
    },
  });

  return response.text ?? '';
}

export async function generateFromMedia(
  media: MediaInfo,
  prompt: string,
  outputDir: string,
  extraContext?: string,
): Promise<GenerateResult> {
  const client = getClient();

  const mediaPart = mediaToPart(media);
  let fullPrompt = prompt;
  if (extraContext) {
    fullPrompt = `[Prior analysis context]\n${extraContext}\n\n${prompt}`;
  }
  const textPart: Part = { text: fullPrompt };

  const response = await client.models.generateContent({
    model: MODEL_ID,
    contents: [{ role: 'user', parts: [mediaPart, textPart] }],
    config: {
      responseModalities: ['TEXT', 'IMAGE'],
      temperature: 0,
    },
  });

  mkdirSync(outputDir, { recursive: true });

  let text = '';
  const imagePaths: string[] = [];
  let imageIndex = 0;

  const parts = response.candidates?.[0]?.content?.parts;
  if (parts) {
    for (const part of parts) {
      if (part.text) {
        text += (text ? '\n' : '') + part.text;
      } else if (part.inlineData) {
        const buffer = Buffer.from(part.inlineData.data!, 'base64');
        const filename = `generated-${imageIndex}.png`;
        const filePath = join(outputDir, filename);
        writeFileSync(filePath, buffer);
        imagePaths.push(filePath);
        imageIndex++;
      }
    }
  }

  if (imagePaths.length === 0) {
    text += (text ? '\n' : '') + '[Warning: No image generated by model]';
  }

  return { text, imagePaths };
}

export async function generateFromMultipleMedia(
  mediaList: MediaInfo[],
  prompt: string,
  outputDir: string,
  extraContext?: string,
): Promise<GenerateResult> {
  const client = getClient();

  const parts: Part[] = mediaList.map((media) => mediaToPart(media));

  let fullPrompt = '';
  if (extraContext) {
    fullPrompt += `[Prior analysis context]\n${extraContext}\n\n`;
  }
  fullPrompt += `[Analyzing ${mediaList.length} files: ${mediaList.map(m => m.path.split('/').pop()).join(', ')}]\n\n${prompt}`;
  parts.push({ text: fullPrompt });

  const response = await client.models.generateContent({
    model: MODEL_ID,
    contents: [{ role: 'user', parts }],
    config: {
      responseModalities: ['TEXT', 'IMAGE'],
      temperature: 0,
    },
  });

  mkdirSync(outputDir, { recursive: true });

  let text = '';
  const imagePaths: string[] = [];
  let imageIndex = 0;

  const responseParts = response.candidates?.[0]?.content?.parts;
  if (responseParts) {
    for (const part of responseParts) {
      if (part.text) {
        text += (text ? '\n' : '') + part.text;
      } else if (part.inlineData) {
        const buffer = Buffer.from(part.inlineData.data!, 'base64');
        const filename = `generated-${imageIndex}.png`;
        const filePath = join(outputDir, filename);
        writeFileSync(filePath, buffer);
        imagePaths.push(filePath);
        imageIndex++;
      }
    }
  }

  if (imagePaths.length === 0) {
    text += (text ? '\n' : '') + '[Warning: No image generated by model]';
  }

  return { text, imagePaths };
}

const PROMPT_CREATION_SYSTEM = `You are an expert image generation prompt engineer. Your job is to take a user's freeform description and optional analysis context about source media, and produce a single, detailed image generation prompt.

Output format: A narrative description of the desired image followed by --- and a JSON config block.

Guidelines:
- Preserve the user's intent completely
- Add technical visual detail: composition, lighting, materials, perspective, color palette, style
- Be specific about spatial relationships and proportions
- If analysis context is provided, incorporate relevant details about the source media
- The narrative should read as a complete image description
- The JSON config block should contain key-value pairs for any structured parameters (style, mood, technique)
- Do NOT include aspect ratio or image size in the prompt â€” those are handled separately via API config

Example output:
A sunlit architectural floor plan rendered in clean line art style, showing a two-bedroom apartment with open kitchen flowing into living area. Walls drawn in dark charcoal lines on white background, furniture indicated with light gray outlines. North arrow and scale bar in bottom-right corner. Dimensions labeled in meters along each wall segment.
---
{"style": "architectural line drawing", "technique": "clean vector illustration", "mood": "professional, precise"}`;

export async function createGenerationPrompt(
  description: string,
  analysisContext?: string,
): Promise<string> {
  const client = getClient();

  let userMessage = description;
  if (analysisContext) {
    userMessage = `[Source media analysis]\n${analysisContext}\n\n[User request]\n${description}`;
  }

  const response = await client.models.generateContent({
    model: MODEL_ID,
    contents: [{ role: 'user', parts: [{ text: userMessage }] }],
    config: {
      systemInstruction: PROMPT_CREATION_SYSTEM,
      temperature: 0,
    },
  });

  const result = response.text ?? '';
  if (!result.trim()) {
    throw new Error('Prompt creation failed: Gemini returned empty response');
  }
  return result;
}

export async function generateWithConfig(
  media: MediaInfo,
  prompt: string,
  outputDir: string,
  imageConfig?: ImageConfig,
): Promise<GenerateResult> {
  const client = getClient();

  const mediaPart = mediaToPart(media);
  const textPart: Part = { text: prompt };

  const config: Record<string, unknown> = {
    responseModalities: ['TEXT', 'IMAGE'],
    temperature: 1,
  };

  if (imageConfig) {
    const imgCfg: Record<string, string> = {};
    if (imageConfig.aspectRatio) imgCfg.aspectRatio = imageConfig.aspectRatio;
    if (imageConfig.imageSize) imgCfg.imageSize = imageConfig.imageSize;
    if (imageConfig.personGeneration) imgCfg.personGeneration = imageConfig.personGeneration;
    if (Object.keys(imgCfg).length > 0) {
      config.imageConfig = imgCfg;
    }
  }

  const response = await client.models.generateContent({
    model: MODEL_ID,
    contents: [{ role: 'user', parts: [mediaPart, textPart] }],
    config,
  });

  mkdirSync(outputDir, { recursive: true });

  let text = '';
  const imagePaths: string[] = [];
  let imageIndex = 0;

  const parts = response.candidates?.[0]?.content?.parts;
  if (parts) {
    for (const part of parts) {
      if (part.text) {
        text += (text ? '\n' : '') + part.text;
      } else if (part.inlineData) {
        const buffer = Buffer.from(part.inlineData.data!, 'base64');
        const filename = `generated-${imageIndex}.png`;
        const filePath = join(outputDir, filename);
        writeFileSync(filePath, buffer);
        imagePaths.push(filePath);
        imageIndex++;
      }
    }
  }

  if (imagePaths.length === 0) {
    text += (text ? '\n' : '') + '[Warning: No image generated by model]';
  }

  return { text, imagePaths };
}
